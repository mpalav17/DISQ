{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['PrecipitationSumInches', 'hrs'], axis = 1)\n",
    "x.to_csv('train_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['PrecipitationSumInches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 18)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.0\n"
     ]
    }
   ],
   "source": [
    "print(x.values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array(x)\n",
    "#y = np.multiply(y,25.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = x[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 18)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x, dtype=float)\n",
    "y = np.array(y, dtype=float)\n",
    "#y = y[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.00000e-05 0.00000e+00 7.35000e-03 1.88000e-03 1.13100e-02 5.00000e-05\n",
      " 1.45630e-01 7.00000e-04 3.70000e-03 6.00000e-05 1.21000e-03 0.00000e+00\n",
      " 7.00000e-05 2.86800e-02 0.00000e+00 3.66000e-03 8.13100e-02 6.25500e-02\n",
      " 0.00000e+00 2.15740e-01 0.00000e+00 0.00000e+00 1.39100e-02 1.31390e-01\n",
      " 1.40000e-03 7.00000e-05 2.76310e-01 0.00000e+00 1.52000e-03 1.88500e-02\n",
      " 2.34000e-03 9.19720e-01 1.06000e-02 3.13900e-02 1.13701e+00 0.00000e+00\n",
      " 1.49820e-01 2.80000e-04 7.52000e-03 2.06360e-01 1.29840e-01 6.20000e-04\n",
      " 9.43200e-02 4.98000e-03 9.51700e-02 1.37732e+00 2.40000e-04 6.10000e-04\n",
      " 2.16000e-03 1.16780e-01 8.68050e-01 0.00000e+00 1.50000e-04 9.04000e-03\n",
      " 5.13000e-03 0.00000e+00 2.49650e-01 0.00000e+00 6.32900e-02 0.00000e+00\n",
      " 2.04400e-01 2.13800e-01 4.78400e-02 0.00000e+00 1.16000e-03 8.34800e-02\n",
      " 2.40000e-04]\n",
      "[9.00000e-05 0.00000e+00 7.35000e-03 1.88000e-03 1.13100e-02 5.00000e-05\n",
      " 4.56300e-02 7.00000e-04 3.70000e-03 6.00000e-05 1.21000e-03 0.00000e+00\n",
      " 7.00000e-05 2.86800e-02 0.00000e+00 3.66000e-03 8.13100e-02 6.25500e-02\n",
      " 0.00000e+00 2.15740e-01 0.00000e+00 0.00000e+00 6.09000e-03 1.11390e-01\n",
      " 1.40000e-03 7.00000e-05 1.86310e-01 0.00000e+00 1.52000e-03 1.88500e-02\n",
      " 2.34000e-03 9.09720e-01 1.06000e-02 2.13900e-02 3.82990e-01 0.00000e+00\n",
      " 1.49820e-01 2.80000e-04 7.52000e-03 3.03640e-01 2.01600e-02 6.20000e-04\n",
      " 2.05680e-01 4.98000e-03 9.51700e-02 1.24732e+00 2.40000e-04 6.10000e-04\n",
      " 2.16000e-03 1.16780e-01 6.58050e-01 0.00000e+00 1.50000e-04 9.04000e-03\n",
      " 5.13000e-03 0.00000e+00 2.39650e-01 0.00000e+00 6.32900e-02 0.00000e+00\n",
      " 1.44000e-02 1.43800e-01 3.78400e-02 0.00000e+00 1.16000e-03 7.34800e-02\n",
      " 2.40000e-04]\n",
      "Mean Absolute Error: 0.08 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor# Instantiate model with 1000 decision trees\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "predictions = rf.predict(x_test)# Calculate the absolute errors\n",
    "print(predictions)\n",
    "errors = abs(predictions - y_test)# Print out the mean absolute error (mae)\n",
    "print(errors)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.94601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.03142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted\n",
       "0     0.00    0.00001\n",
       "1     0.56    0.94601\n",
       "2     0.00    0.00000\n",
       "3     0.00    0.46146\n",
       "4     0.00    0.25457\n",
       "..     ...        ...\n",
       "62    0.00    0.00457\n",
       "63    0.00    0.00000\n",
       "64    0.00    0.00001\n",
       "65    0.00    0.00071\n",
       "66    0.00    1.03142\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan %.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-b37ced1946fb>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = 100 * (errors / y_test)# Calculate and display accuracy\n",
      "<ipython-input-87-b37ced1946fb>:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mape = 100 * (errors / y_test)# Calculate and display accuracy\n"
     ]
    }
   ],
   "source": [
    "mape = 100 * (errors / y_test)# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(range(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58333333, 0.49206349, 0.39655172, ..., 0.61904762, 0.3       ,\n",
       "        0.45833333],\n",
       "       [0.33333333, 0.3015873 , 0.29310345, ..., 0.42857143, 0.5       ,\n",
       "        0.33333333],\n",
       "       [0.36111111, 0.25396825, 0.17241379, ..., 0.04761905, 0.2       ,\n",
       "        0.0625    ],\n",
       "       ...,\n",
       "       [0.33333333, 0.22222222, 0.13793103, ..., 0.14285714, 0.1       ,\n",
       "        0.125     ],\n",
       "       [0.51388889, 0.34920635, 0.18965517, ..., 0.28571429, 0.2       ,\n",
       "        0.27083333],\n",
       "       [0.52777778, 0.44444444, 0.37931034, ..., 0.23809524, 0.2       ,\n",
       "        0.14583333]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = min_max_scaler.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12568306],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04371585],\n",
       "       [0.        ],\n",
       "       [0.0273224 ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.0136612 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.0136612 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.        ],\n",
       "       [0.04098361],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0273224 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03005464],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02185792],\n",
       "       [0.02185792],\n",
       "       [0.04644809],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.20218579],\n",
       "       [0.03005464],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01912568],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05464481],\n",
       "       [0.07377049],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.36612022],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.66939891],\n",
       "       [0.2568306 ],\n",
       "       [0.03825137],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05191257],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.42622951],\n",
       "       [0.47814208],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.15027322],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.40710383],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07377049],\n",
       "       [0.06557377],\n",
       "       [0.13387978],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01912568],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.08469945],\n",
       "       [0.96448087],\n",
       "       [0.41530055],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02459016],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0136612 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01912568],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.26775956],\n",
       "       [0.00546448],\n",
       "       [0.05191257],\n",
       "       [0.06010929],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.13934426],\n",
       "       [0.18579235],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.09562842],\n",
       "       [1.        ],\n",
       "       [0.03551913],\n",
       "       [0.05737705],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00819672],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.38797814],\n",
       "       [0.00273224],\n",
       "       [0.02459016],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08196721],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.15300546],\n",
       "       [0.41256831],\n",
       "       [0.01092896],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = min_max_scaler.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 18, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x = x[:,:,None]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.58333333],\n",
       "        [0.49206349],\n",
       "        [0.39655172],\n",
       "        ...,\n",
       "        [0.61904762],\n",
       "        [0.3       ],\n",
       "        [0.45833333]],\n",
       "\n",
       "       [[0.33333333],\n",
       "        [0.3015873 ],\n",
       "        [0.29310345],\n",
       "        ...,\n",
       "        [0.42857143],\n",
       "        [0.5       ],\n",
       "        [0.33333333]],\n",
       "\n",
       "       [[0.36111111],\n",
       "        [0.25396825],\n",
       "        [0.17241379],\n",
       "        ...,\n",
       "        [0.04761905],\n",
       "        [0.2       ],\n",
       "        [0.0625    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.33333333],\n",
       "        [0.22222222],\n",
       "        [0.13793103],\n",
       "        ...,\n",
       "        [0.14285714],\n",
       "        [0.1       ],\n",
       "        [0.125     ]],\n",
       "\n",
       "       [[0.51388889],\n",
       "        [0.34920635],\n",
       "        [0.18965517],\n",
       "        ...,\n",
       "        [0.28571429],\n",
       "        [0.2       ],\n",
       "        [0.27083333]],\n",
       "\n",
       "       [[0.52777778],\n",
       "        [0.44444444],\n",
       "        [0.37931034],\n",
       "        ...,\n",
       "        [0.23809524],\n",
       "        [0.2       ],\n",
       "        [0.14583333]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12568306],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04371585],\n",
       "       [0.        ],\n",
       "       [0.0273224 ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.0136612 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.0136612 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.        ],\n",
       "       [0.04098361],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0273224 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03005464],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02185792],\n",
       "       [0.02185792],\n",
       "       [0.04644809],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.20218579],\n",
       "       [0.03005464],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01912568],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05464481],\n",
       "       [0.07377049],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.36612022],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.66939891],\n",
       "       [0.2568306 ],\n",
       "       [0.03825137],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05191257],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.42622951],\n",
       "       [0.47814208],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.15027322],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.40710383],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07377049],\n",
       "       [0.06557377],\n",
       "       [0.13387978],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01912568],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01639344],\n",
       "       [0.08469945],\n",
       "       [0.96448087],\n",
       "       [0.41530055],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02459016],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0136612 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01912568],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.26775956],\n",
       "       [0.00546448],\n",
       "       [0.05191257],\n",
       "       [0.06010929],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.13934426],\n",
       "       [0.18579235],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.09562842],\n",
       "       [1.        ],\n",
       "       [0.03551913],\n",
       "       [0.05737705],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00819672],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.38797814],\n",
       "       [0.00273224],\n",
       "       [0.02459016],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08196721],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.15300546],\n",
       "       [0.41256831],\n",
       "       [0.01092896],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00546448],\n",
       "       [0.00273224],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00273224]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 18, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(20, activation='sigmoid', input_shape=(None, 1)))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(LSTM((1),return_sequences = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, None, 20)          40        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, None, 10)          210       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, None, 1)           11        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 273\n",
      "Trainable params: 273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 0.2788 - mse: 0.0866 - val_loss: 0.2585 - val_mse: 0.0878\n",
      "Epoch 2/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.2409 - mse: 0.0669 - val_loss: 0.2214 - val_mse: 0.0700\n",
      "Epoch 3/250\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2044 - mse: 0.0508 - val_loss: 0.1859 - val_mse: 0.0555\n",
      "Epoch 4/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.1696 - mse: 0.0376 - val_loss: 0.1521 - val_mse: 0.0441\n",
      "Epoch 5/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1364 - mse: 0.0272 - val_loss: 0.1198 - val_mse: 0.0353\n",
      "Epoch 6/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1046 - mse: 0.0198 - val_loss: 0.0885 - val_mse: 0.0288\n",
      "Epoch 7/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0735 - mse: 0.0142 - val_loss: 0.0575 - val_mse: 0.0243\n",
      "Epoch 8/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0423 - mse: 0.0106 - val_loss: 0.0285 - val_mse: 0.0216\n",
      "Epoch 9/250\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0306 - mse: 0.0090 - val_loss: 0.0381 - val_mse: 0.0212\n",
      "Epoch 10/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0318 - mse: 0.0089 - val_loss: 0.0305 - val_mse: 0.0215\n",
      "Epoch 11/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0268 - mse: 0.0094 - val_loss: 0.0283 - val_mse: 0.0218\n",
      "Epoch 12/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0264 - mse: 0.0093 - val_loss: 0.0284 - val_mse: 0.0216\n",
      "Epoch 13/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0259 - mse: 0.0094 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 14/250\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0256 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 15/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 16/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 17/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 18/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 19/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 20/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 21/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 22/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 23/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 24/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 25/250\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 26/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 27/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 28/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 29/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 30/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 31/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 32/250\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 33/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 34/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 35/250\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 36/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 37/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 38/250\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 39/250\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 40/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0252 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 41/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 42/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 43/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 44/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 45/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0252 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 46/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 47/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 48/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 49/250\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 50/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 51/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 52/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 53/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0218\n",
      "Epoch 54/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 55/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 56/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 57/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 58/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 59/250\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 60/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 61/250\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0258 - mse: 0.0093 - val_loss: 0.0286 - val_mse: 0.0218\n",
      "Epoch 62/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0260 - mse: 0.0093 - val_loss: 0.0280 - val_mse: 0.0218\n",
      "Epoch 63/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0256 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 64/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 65/250\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 66/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 67/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 68/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0283 - val_mse: 0.0217\n",
      "Epoch 69/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0256 - mse: 0.0094 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 70/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 71/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 72/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 73/250\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 74/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0256 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 75/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 76/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0287 - val_mse: 0.0216\n",
      "Epoch 77/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0260 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 78/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 79/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 80/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 81/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 82/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 83/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 84/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 85/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 86/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 87/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 88/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0218\n",
      "Epoch 89/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 90/250\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 91/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0252 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 92/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 93/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0218\n",
      "Epoch 94/250\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 95/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 96/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 97/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 98/250\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0279 - val_mse: 0.0218\n",
      "Epoch 99/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0256 - mse: 0.0094 - val_loss: 0.0281 - val_mse: 0.0218\n",
      "Epoch 100/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0285 - val_mse: 0.0218\n",
      "Epoch 101/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0259 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 102/250\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 103/250\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 104/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0218\n",
      "Epoch 105/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 106/250\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 107/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 108/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 109/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0257 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 110/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 111/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 112/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 113/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 114/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 115/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 116/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0279 - val_mse: 0.0218\n",
      "Epoch 117/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 118/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 119/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0279 - val_mse: 0.0218\n",
      "Epoch 120/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0257 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 121/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 122/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 123/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 124/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 125/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 126/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 127/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 128/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 129/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 130/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 131/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 132/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 133/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 134/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 135/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0256 - mse: 0.0094 - val_loss: 0.0289 - val_mse: 0.0216\n",
      "Epoch 136/250\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0260 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 137/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0261 - mse: 0.0093 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 138/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0258 - mse: 0.0094 - val_loss: 0.0283 - val_mse: 0.0217\n",
      "Epoch 139/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 140/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 141/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 142/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 143/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0257 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 144/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0257 - mse: 0.0093 - val_loss: 0.0279 - val_mse: 0.0218\n",
      "Epoch 145/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 146/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0251 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 147/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 148/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 149/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 150/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 151/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 152/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 153/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 154/250\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 155/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 156/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0257 - mse: 0.0094 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 157/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 158/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 159/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 160/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 161/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 162/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 163/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 164/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 165/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 166/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 167/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0281 - val_mse: 0.0218\n",
      "Epoch 168/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0218\n",
      "Epoch 169/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 170/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 171/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0256 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 172/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 173/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0256 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 174/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 175/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 176/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 177/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 178/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 179/250\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 180/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 181/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 182/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0283 - val_mse: 0.0217\n",
      "Epoch 183/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0257 - mse: 0.0094 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 184/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0256 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 185/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 186/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0279 - val_mse: 0.0218\n",
      "Epoch 187/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0258 - mse: 0.0093 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 188/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 189/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 190/250\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 191/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 192/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 193/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 194/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 195/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 196/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 197/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0251 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 198/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 199/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0251 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 200/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 201/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0281 - val_mse: 0.0217\n",
      "Epoch 202/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 203/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 204/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 205/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0284 - val_mse: 0.0218\n",
      "Epoch 206/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0257 - mse: 0.0093 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 207/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0257 - mse: 0.0094 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 208/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0256 - mse: 0.0093 - val_loss: 0.0287 - val_mse: 0.0216\n",
      "Epoch 209/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0259 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 210/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0256 - mse: 0.0093 - val_loss: 0.0280 - val_mse: 0.0218\n",
      "Epoch 211/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0257 - mse: 0.0093 - val_loss: 0.0281 - val_mse: 0.0217\n",
      "Epoch 212/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0285 - val_mse: 0.0216\n",
      "Epoch 213/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 214/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 215/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0255 - mse: 0.0094 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 216/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 217/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0279 - val_mse: 0.0218\n",
      "Epoch 218/250\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0273 - val_mse: 0.0217\n",
      "Epoch 219/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 220/250\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 221/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0256 - mse: 0.0094 - val_loss: 0.0282 - val_mse: 0.0217\n",
      "Epoch 222/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0256 - mse: 0.0094 - val_loss: 0.0285 - val_mse: 0.0216\n",
      "Epoch 223/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0258 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 224/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 225/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 226/250\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0252 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 227/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 228/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 229/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 230/250\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0253 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 231/250\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0218\n",
      "Epoch 232/250\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 233/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 234/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 235/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 236/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0256 - mse: 0.0094 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 237/250\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0278 - val_mse: 0.0218\n",
      "Epoch 238/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0275 - val_mse: 0.0217\n",
      "Epoch 239/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0218\n",
      "Epoch 240/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 241/250\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0281 - val_mse: 0.0217\n",
      "Epoch 242/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0274 - val_mse: 0.0217\n",
      "Epoch 243/250\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 244/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0277 - val_mse: 0.0217\n",
      "Epoch 245/250\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 246/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0280 - val_mse: 0.0217\n",
      "Epoch 247/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0254 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n",
      "Epoch 248/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - mse: 0.0094 - val_loss: 0.0278 - val_mse: 0.0217\n",
      "Epoch 249/250\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0279 - val_mse: 0.0217\n",
      "Epoch 250/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0217\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs = 250, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(x_test)\n",
    "res_s = res[:]\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(67), res_s, c = 'r')\n",
    "plt.plot(range(67), y_test, c = 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
